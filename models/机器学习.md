## 机器学习

---

### 你不是在学习机器学习，而是在向机器学习

人们总说人生是一条长河，是一个连续的过程，但是现在更多的证明，人生其实是很多点组成的。

这些点从何而来：选择。

关键词：不再是连续的微积分，而是离散的概率。

就像是机器学习的分类模型，一个又一个概率型选择题，造就了一个又一个 AI 奇迹。

所以吴老师说你要学好机器学习你就要掌握一下概率论，统计学，离散数学，图论，逻辑学，这些东西都是有助于人生进行选择的重要工具。如何判断你的下一步选择，决定了你的下一个人生分叉口。理论上，每一个选择支线上都有一个你的分叉出现，平行宇宙是不是也是在宇宙做出无数个选择后的结果。

### 深度学习

最不可解的一个东西。来自人脑的神经元为最初的发想。

不知道内部原理的人会觉得很高大上，但是知道他是什么的人，知道每一个神经元在干什么，简单！但是无数的简单放在一起，以亿为单位的组成一个巨大的网络，就变成了一个强大的系统。

计算机的最底层原理也只是0和1的运算而已。却能构成现在你手中如此强大的计算核心。人们说计算机的本质其实就是无数的计算而已，其实神经网络也是在计算而已。

人脑也是在计算而已。

在我看来他们都是不可解的。

最不可解的，就是最简单的东西往往是最强大的，01运算，激活函数。

何为深度学习，就是做着看似简单的学习任务，看似没什么难度，想让整个知识体系变得强大，最重要的关键词就是“连接”！


### 迁移学习

站在巨人的肩膀上，连机器都会了，很多人还不会。

有些人可能真的觉得学习新的东西和技能没必要，只要坚持自己现在的生活方式就好？

说实话，我没法反驳，也许他们是对的，毕竟人生这么短，这么努力要干嘛，但是就是因为**不知道为什么要努力**所以才要努力，因为还是那种感觉，就是宇宙就算要给你惊喜，也要给有准备的你。

学习机器的迁移学习，将前人的模型加以利用，成为自己的参数，如何学习前人的模型呢。套路！

总的来说更多的数据，可以得到更好的模型。

那么迁移模型就是来自于大量的训练数据下的模型，就像一个高材生你花了重金雇进来给你工作，为什么他值钱，就是因为，他花了大量的时间教材经历进行了自我学习，这些经历，教材，都是他的学习数据，他学习的时间都是成本。

迁移学习的本质就是更多的数据塑造更好的模型，然后我们直接用这些模型，特化为我们自己的模型。

### 机器学习中的过拟合和欠拟合

过拟合相当于你拿着课本学的太细了，出去就不会了，欠拟合相当于你课本都没学够，不知道怎么活学活用课本的题呢，就更别说出去用了。

不管那种都不太好，所以学习的时候，应当一边学习，一边思考，思考你学习的知识的应用领域应该是怎么样的，并且不断调整学习率，重要的是在达到阈值的时候，要质变了的时候，学习率虽然很小，但是再努力一点就可以到达梯度0！

我们知道迁移学习是一个很好的结果过拟合和欠拟合的方法，你学习的时候，直接跳过原理，而用前人总结好的模型套用，就相当于一个迁移学习，模型微调，就相当于，你将前人的模型进行自己的问题的一个更具体的应用！

### 强化学习还没成熟，但是未来不会缺席

关键词：马尔可夫链

越是距离现在久远的过去的事件，对现在的影响越是小，机器的决策主要根据过去的最近的一些状况。

在这个不确定的世界，我们掌握控制论，临机应变，做好对应机制才是最重要的。

### 机器如何学习

机器是如何学习的，其实和人一样，分为了演绎，归纳，和演化三种方式。完全理性的推理是演绎，函数式编程就是这一类的方法，纯理性，不接受不确定性，公式定理都是这样推理出来的。

归纳是现在的机器学习最主要的方法，当然人类也是，人类通过经验学习，总结规律，就是一般意义上的学习，机器学习也是一样。其中还有各种流派，比如连接主义的神经网络，贝叶斯主义的概率图，贝叶斯网络，马尔可夫随机场，演化最典型的是遗传算法，其实三种学习方法缺一不可。未来的人工智能想要真正获得只能，三者缺一不可。

机器为什么可以通过学习进行预测，是因为大数定律的存在，小样本的不断抽样调查，似乎可以无限接近期望，这就是归纳法大致有效的原因，根据中心极限定理，大量随机变量的均值经过适当标准化，近似服从正态分布。但是归纳这么重要，但是我们无法穷尽掌握宇宙的真理，机器学习的预测也永远无法百分百预测准确。这是为什么呢。

不要只想正态分布的存在，还有一种重要的分布模型，就是幂律分布。

### 正态分布和幂律分布

这两个分布的区别来说，正态分布的各个因素之间是没有联系，也就是互不影响，但是幂律分布的事物各个因素之间是相互联系，相互影响的！

幂律法则指在任何一件事物中，极少数的关键事物带来绝大多数的收益，其他大多数普通事物只获得少量收益。平时经常能见到的马太效应，长尾理论，帕累托法则（二八法则）其实就是和幂次法则的意思差不多。

由于幂律分布的存在，造成大数定律失效，个体的影响非常大，黑天鹅事件终将发生。不确定，不可预测是这个世界的真实面貌。所以很难完全进行经验学习！归纳学习就会失效！由此，诞生了控制论，在不确定性中提高应对危机的能力就显得至关重要了。很多软件开发也倾向于选择敏捷开发，缩短循环周期，面对不确定，更快的进行反应。这是一种演化的方法。

### 幂律分布和熵增定律

幂律分布的曲线是一条开放的曲线，是宇宙诞生时候的样子，它象征着环境是开放的，耗散的系统，和外界进行交互的，充满活力而不是封闭的，但是由于熵增，系统会不断趋于变成，正态分布的样子，然后宇宙也许就会终结。这也许正是宇宙内部的数学原理。

其实我觉得应该感谢幂律分布的存在，它让这个宇宙充满不确定性，而不是正态分布那样，可以被机器学习预测，想象一个规律确定的世界，人类被机器支配这件事估计也不远了。

正是由于幂律分布， 这个世界才充满了惊喜，充满了活力，负熵才能不断重新更新这个世界，而不是变得沉寂无聊。

### Dropout防止过拟合

机器学习中有一种策略，让部分神经元跳过学习直接丢弃权重，是为了防止过拟合。这告诉我们不要太看重某个原理，没有任何特征，原理是可以无所不包的，广泛的学习，对各种内容不只是要重点提取特征，更需要多各个重要的内容进行均匀分布。让所有的重点都覆盖到。
